<h1 align="center">
  <a href="https://github.com/SakanaAI/AI-Scientist/blob/main/docs/logo_2.png">
    <img src="docs/logo_2.png" width="215" /></a><br>
  <b>The AI Scientist: Towards Fully Automated</b><br>
  <b>Open-Ended Scientific Discovery ğŸ§‘â€ğŸ”¬</b><br>
</h1>

<p align="center">
  ğŸ“š <a href="https://arxiv.org/abs/2408.06292">[Paper]</a> |
  ğŸ“ <a href="https://sakana.ai/ai-scientist/">[Blog Post]</a> |
  ğŸ“‚ <a href="https://drive.google.com/drive/folders/1G7A0wTqfXVa-cpexjk0oaXakaSJwffEt">[Drive Folder]</a>
</p>

One of the grand challenges of artificial intelligence is developing agents capable of conducting scientific research and discovering new knowledge. While frontier models have already been used to aid human scientistsâ€”for example, for brainstorming ideas or writing codeâ€”they still require extensive manual supervision or are heavily constrained to specific tasks.

We're excited to introduce **The AI Scientist**, the first comprehensive system for fully automatic scientific discovery, enabling Foundation Models such as Large Language Models (LLMs) to perform research independently.

We provide all runs and data from our paper [here](https://drive.google.com/drive/folders/1G7A0wTqfXVa-cpexjk0oaXakaSJwffEt?usp=sharing), where we run each base model on each template for approximately 50 ideas. We *highly* recommend reading through some of the [Claude papers](https://drive.google.com/drive/folders/1Mmpz6M1FK4q8e-SewgZcUzdeD0Q2zC39?usp=sharing) to get a sense of the system's strengths and weaknesses. Here are some example papers generated by **The AI Scientist** ğŸ“:

1. [DualScale Diffusion: Adaptive Feature Balancing for Low-Dimensional Generative Models](https://github.com/SakanaAI/AI-Scientist/blob/main/example_papers/adaptive_dual_scale_denoising.pdf)
2. [Multi-scale Grid Noise Adaptation: Enhancing Diffusion Models For Low-dimensional Data](https://github.com/SakanaAI/AI-Scientist/blob/main/example_papers/grid_based_noise_adaptation.pdf)
3. [GAN-Enhanced Diffusion: Boosting Sample Quality and Diversity](https://github.com/SakanaAI/AI-Scientist/blob/main/example_papers/gan_diffusion.pdf)
4. [DualDiff: Enhancing Mode Capture in Low-dimensional Diffusion Models via Dual-expert Denoising](https://github.com/SakanaAI/AI-Scientist/tree/main/example_papers/dual_expert_denoiser.pdf) 
5. [StyleFusion: Adaptive Multi-style Generation in Character-Level Language Models](https://github.com/SakanaAI/AI-Scientist/blob/main/example_papers/multi_style_adapter.pdf)
6. [Adaptive Learning Rates for Transformers via Q-Learning](https://github.com/SakanaAI/AI-Scientist/tree/main/example_papers/rl_lr_adaptation.pdf)
7. [Unlocking Grokking: A Comparative Study of Weight Initialization Strategies in Transformer Models](https://github.com/SakanaAI/AI-Scientist/tree/main/example_papers/weight_initialization_grokking.pdf)
8. [Grokking Accelerated: Layer-wise Learning Rates for Transformer Generalization](https://github.com/SakanaAI/AI-Scientist/tree/main/example_papers/layerwise_lr_grokking.pdf)
9. [Grokking Through Compression: Unveiling Sudden Generalization via Minimal Description Length](https://github.com/SakanaAI/AI-Scientist/tree/main/example_papers/mdl_grokking_correlation.pdf)
10. [Accelerating Mathematical Insight: Boosting Grokking Through Strategic Data Augmentation](https://github.com/SakanaAI/AI-Scientist/tree/main/example_papers/data_augmentation_grokking.pdf)

> **Note:**  
> **Caution!** This codebase will execute LLM-written code. There are various risks and challenges associated with this autonomy, including the use of potentially dangerous packages, web access, and potential spawning of processes. Use at your own discretion. Please make sure to [containerize](#containerization) and restrict web access appropriately.

<p align="center">
  <a href="https://github.com/SakanaAI/AI-Scientist/blob/main/example_papers/adaptive_dual_scale_denoising/adaptive_dual_scale_denoising.pdf"><img src="https://github.com/SakanaAI/AI-Scientist/blob/main/docs/anim-ai-scientist.gif" alt="Adaptive Dual Scale Denoising" width="80%" />
</a></p>

## Table of Contents

1. [Introduction](#introduction)
2. [Requirements](#requirements)
   - [Installation](#installation)
   - [Supported Models and API Keys](#supported-models-and-api-keys)
3. [Setting Up the Templates](#setting-up-the-templates)
   - [NanoGPT Template](#nanogpt-template)
   - [2D Diffusion Template](#2d-diffusion-template)
   - [Grokking Template](#grokking-template)
4. [Run AI Scientist Paper Generation Experiments](#run-ai-scientist-paper-generation-experiments)
5. [Getting an LLM-Generated Paper Review](#getting-an-llm-generated-paper-review)
6. [Making Your Own Template](#making-your-own-template)
   - [Community-Contributed Templates](#community-contributed-templates)
7. [Template Resources](#template-resources)
8. [Citing The AI Scientist](#citing-the-ai-scientist)
9. [Frequently Asked Questions](#frequently-asked-questions)
10. [Containerization](#containerization)

## Introduction

We provide three templates, which were used in our paper, covering the following domains: **NanoGPT**, **2D Diffusion**, and **Grokking**. These templates enable The AI Scientist to generate ideas and conduct experiments in these areas. We accept contributions of new templates from the community, but please note that they are not maintained by us. All other templates beyond the three provided are community contributions.

## Requirements

This code is designed to run on Linux with NVIDIA GPUs using CUDA and PyTorch. Support for other GPU architectures may be possible by following the [PyTorch guidelines](https://pytorch.org/get-started/locally/). The current templates would likely take an infeasible amount of time on CPU-only machines. Running on other operating systems may require significant adjustments.

### Installation

```bash
conda create -n ai_scientist python=3.11
conda activate ai_scientist
# Install pdflatex
sudo apt-get install texlive-full

# Install PyPI requirements
pip install -r requirements.txt
```

**Note:** Installing `texlive-full` can take a long time. You may need to [hold Enter](https://askubuntu.com/questions/956006/pregenerating-context-markiv-format-this-may-take-forever) during the installation.

### Supported Models and API Keys

We support a wide variety of models, including open-weight and API-only models. In general, we recommend using only frontier models above the capability of the original GPT-4. To see a full list of supported models, see [here](https://github.com/SakanaAI/AI-Scientist/blob/main/ai_scientist/llm.py).

#### OpenAI API (GPT-4o, GPT-4o-mini, o1 models)

By default, this uses the `OPENAI_API_KEY` environment variable.

#### Anthropic API (Claude Sonnet 3.5)

By default, this uses the `ANTHROPIC_API_KEY` environment variable.

##### Claude Models via Bedrock

For Claude models provided by [Amazon Bedrock](https://aws.amazon.com/bedrock/), please install these additional packages:

```bash
pip install anthropic[bedrock]
```

Next, specify a set of valid [AWS Credentials](https://docs.aws.amazon.com/cli/v1/userguide/cli-configure-envvars.html) and the target [AWS Region](https://docs.aws.amazon.com/bedrock/latest/userguide/bedrock-regions.html):

Set the environment variables: `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `AWS_REGION_NAME`.

##### Claude Models via Vertex AI

For Claude models provided by [Vertex AI Model Garden](https://cloud.google.com/model-garden?hl=en), please install these additional packages:

```bash
pip install google-cloud-aiplatform
pip install anthropic[vertex]
```

Next, set up valid authentication for a [Google Cloud project](https://cloud.google.com/vertex-ai/docs/authentication), for example by providing the region and project ID:

```bash
export CLOUD_ML_REGION="REGION"           # for Model Garden call
export ANTHROPIC_VERTEX_PROJECT_ID="PROJECT_ID"  # for Model Garden call
export VERTEXAI_LOCATION="REGION"         # for Aider/LiteLLM call
export VERTEXAI_PROJECT="PROJECT_ID"      # for Aider/LiteLLM call
```

#### DeepSeek API (DeepSeek-Coder-V2)

By default, this uses the `DEEPSEEK_API_KEY` environment variable.

#### OpenRouter API (Llama3.1)

By default, this uses the `OPENROUTER_API_KEY` environment variable.

#### Semantic Scholar API (Literature Search)

Our code can also optionally use a Semantic Scholar API Key (`S2_API_KEY`) for higher throughput [if you have one](https://www.semanticscholar.org/product/api), though it should work without it in principle. If you have problems with Semantic Scholar, you can skip the literature search and citation phases of paper generation.

Be sure to provide the key for the model used for your runs, e.g.:

```bash
export OPENAI_API_KEY="YOUR KEY HERE"
export S2_API_KEY="YOUR KEY HERE"
```

## Setting Up the Templates

This section provides instructions for setting up each of the three templates used in our paper. Before running The AI Scientist experiments, please ensure you have completed the setup steps for the templates you are interested in.

### NanoGPT Template

**Description:** This template investigates transformer-based autoregressive next-token prediction tasks.

**Setup Steps:**

1. **Prepare the data:**

   ```bash
   python data/enwik8/prepare.py
   python data/shakespeare_char/prepare.py
   python data/text8/prepare.py
   ```

2. **Create baseline runs (machine dependent):**

   ```bash
   # Set up NanoGPT baseline run
   # NOTE: YOU MUST FIRST RUN THE PREPARE SCRIPTS ABOVE!
   cd templates/nanoGPT
   python experiment.py --out_dir run_0
   python plot.py
   ```

### 2D Diffusion Template

**Description:** This template studies improving the performance of diffusion generative models on low-dimensional datasets.

**Setup Steps:**

1. **Install dependencies:**

   ```bash
   # Set up 2D Diffusion
   git clone https://github.com/gregversteeg/NPEET.git
   cd NPEET
   pip install .
   pip install scikit-learn
   ```

2. **Create baseline runs:**

   ```bash
   # Set up 2D Diffusion baseline run
   cd templates/2d_diffusion
   python experiment.py --out_dir run_0
   python plot.py
   ```

### Grokking Template

**Description:** This template investigates questions about generalization and learning speed in deep neural networks.

**Setup Steps:**

1. **Install dependencies:**

   ```bash
   # Set up Grokking
   pip install einops
   ```

2. **Create baseline runs:**

   ```bash
   # Set up Grokking baseline run
   cd templates/grokking
   python experiment.py --out_dir run_0
   python plot.py
   ```

## Run AI Scientist Paper Generation Experiments

**Note:** Please ensure the setup steps above are completed before running these experiments.

```bash
conda activate ai_scientist
# Run the paper generation.
python launch_scientist.py --model "gpt-4o-2024-05-13" --experiment nanoGPT_lite --num-ideas 2
python launch_scientist.py --model "claude-3-5-sonnet-20241022" --experiment nanoGPT_lite --num-ideas 2
```

If you have more than one GPU, use the `--parallel` option to parallelize ideas across multiple GPUs.

## Getting an LLM-Generated Paper Review

```python
import openai
from ai_scientist.perform_review import load_paper, perform_review

client = openai.OpenAI()
model = "gpt-4o-2024-05-13"

# Load paper from PDF file (raw text)
paper_txt = load_paper("report.pdf")

# Get the review dictionary
review = perform_review(
    paper_txt,
    model,
    client,
    num_reflections=5,
    num_fs_examples=1,
    num_reviews_ensemble=5,
    temperature=0.1,
)

# Inspect review results
review["Overall"]    # Overall score (1-10)
review["Decision"]   # 'Accept' or 'Reject'
review["Weaknesses"] # List of weaknesses (strings)
```

To run batch analysis:

```bash
cd review_iclr_bench
python iclr_analysis.py --num_reviews 500 --batch_size 100 --num_fs_examples 1 --num_reflections 5 --temperature 0.1 --num_reviews_ensemble 5
```

## Making Your Own Template

If there is an area of study you would like **The AI Scientist** to explore, it is straightforward to create your own templates. In general, follow the structure of the existing templates, which consist of:

- `experiment.py` â€” This is the main script where the core content is. It takes an argument `--out_dir`, which specifies where it should create the folder and save the relevant information from the run.
- `plot.py` â€” This script takes the information from the `run` folders and creates plots. The code should be clear and easy to edit.
- `prompt.json` â€” Put information about your template here.
- `seed_ideas.json` â€” Place example ideas here. You can also try to generate ideas without any examples and then pick the best one or two to put here.
- `latex/template.tex` â€” We recommend using our LaTeX folder but be sure to replace the pre-loaded citations with ones that you expect to be more relevant.

The key to making new templates work is matching the base filenames and output JSONs to the existing format; everything else is free to change.
You should also ensure that the `template.tex` file is updated to use the correct citation style / base plots for your template.

### Community-Contributed Templates

We welcome community contributions in the form of new templates. While these are not maintained by us, we are delighted to highlight your templates to others. Below, we list community-contributed templates along with links to their pull requests (PRs):

- Infectious Disease Modeling (`seir`) - [PR #137](https://github.com/SakanaAI/AI-Scientist/pull/137)
- Image Classification with MobileNetV3 (`mobilenetV3`) - [PR #141](https://github.com/SakanaAI/AI-Scientist/pull/141)
- Sketch RNN (`sketch_rnn`) - [PR #143](https://github.com/SakanaAI/AI-Scientist/pull/143)

*This section is reserved for community contributions. Please submit a pull request to add your template to the list! Please describe the template in the PR description, and also show examples of the generated papers.*

## Template Resources

We provide three templates, which heavily use code from other repositories, credited below:

- **NanoGPT Template** uses code from [NanoGPT](https://github.com/karpathy/nanoGPT) and this [PR](https://github.com/karpathy/nanoGPT/pull/254).
- **2D Diffusion Template** uses code from [tiny-diffusion](https://github.com/tanelp/tiny-diffusion), [ema-pytorch](https://github.com/lucidrains/ema-pytorch), and [Datasaur](https://www.research.autodesk.com/publications/same-stats-different-graphs/).
- **Grokking Template** uses code from [Sea-Snell/grokking](https://github.com/Sea-Snell/grokking) and [danielmamay/grokking](https://github.com/danielmamay/grokking).

We would like to thank the developers of the open-source models and packages for their contributions and for making their work available.

## Citing The AI Scientist

If you use **The AI Scientist** in your research, please cite it as follows:

```
@article{lu2024aiscientist,
  title={The {AI} {S}cientist: Towards Fully Automated Open-Ended Scientific Discovery},
  author={Lu, Chris and Lu, Cong and Lange, Robert Tjarko and Foerster, Jakob and Clune, Jeff and Ha, David},
  journal={arXiv preprint arXiv:2408.06292},
  year={2024}
}
```

## Frequently Asked Questions

We recommend reading our paper first for any questions you have on The AI Scientist.

**Why am I missing files when running The AI Scientist?**

Ensure you have completed all the setup and preparation steps before the main experiment script.

**Why has a PDF or a review not been generated?**

The AI Scientist finishes an idea with a success rate that depends on the template, the base foundation model, and the complexity of the idea. We advise referring to our main paper. The highest success rates are observed with Claude Sonnet 3.5. Reviews are best done with GPT-4o; all other models have issues with positivity bias or failure to conform to required outputs.

**What is the cost of each idea generated?**

Typically less than $15 per paper with Claude Sonnet 3.5. We recommend DeepSeek Coder V2 for a much more cost-effective approach. A good place to look for new models is the [Aider leaderboard](https://aider.chat/docs/leaderboards/).

**How do I change the base conference format associated with the write-ups?**

Change the base `template.tex` files contained within each template.

**How do I run The AI Scientist for different subject fields?**

Please refer to the instructions for different templates. In this current iteration, this is restricted to ideas that can be expressed in code. However, lifting this restriction would represent exciting future work! :)

**How do I add support for a new foundation model?**

You may modify `ai_scientist/llm.py` to add support for a new foundation model. We do not advise using any model that is significantly weaker than GPT-4 level for **The AI Scientist**.

**Why do I need to run the baseline runs myself?**

These appear as `run_0` and should be run per machine you execute **The AI Scientist** on for accurate run-time comparisons due to hardware differences.

**What if I have problems accessing the Semantic Scholar API?**

We use the Semantic Scholar API to check ideas for novelty and collect citations for the paper write-up. You may be able to skip these phases if you don't have an API key or the API is slow to access.

## Containerization

We include a [community-contributed](https://github.com/SakanaAI/AI-Scientist/pull/21) Docker image that may assist with your containerization efforts in `experimental/Dockerfile`.

You can use this image like this:

```bash
# Endpoint Script
docker run -e OPENAI_API_KEY=$OPENAI_API_KEY -v `pwd`/templates:/app/AI-Scientist/templates <AI_SCIENTIST_IMAGE> \
  --model gpt-4o-2024-05-13 \
  --experiment 2d_diffusion \
  --num-ideas 2
```

```bash
# Interactive
docker run -it -e OPENAI_API_KEY=$OPENAI_API_KEY \
  --entrypoint /bin/bash \
  <AI_SCIENTIST_IMAGE>
```

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=SakanaAI/AI-Scientist&type=Date)](https://star-history.com/#SakanaAI/AI-Scientist&Date)

## ç›®æ¬¡

1. [ã¯ã˜ã‚ã«](#ã¯ã˜ã‚ã«)
2. [è¦ä»¶](#è¦ä»¶)
   - [ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«](#ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«)
   - [ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ã¨APIã‚­ãƒ¼](#ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ã¨APIã‚­ãƒ¼)
3. [ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®è¨­å®š](#ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®è¨­å®š)
   - [NanoGPTãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ](#nanogptãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ)
   - [2D Diffusionãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ](#2d-diffusionãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ)
   - [Grokkingãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ](#grokkingãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ)
4. [AI Scientistã®è«–æ–‡ç”Ÿæˆå®Ÿé¨“ã‚’å®Ÿè¡Œã™ã‚‹](#ai-scientistã®è«–æ–‡ç”Ÿæˆå®Ÿé¨“ã‚’å®Ÿè¡Œã™ã‚‹)
5. [LLMç”Ÿæˆã®è«–æ–‡ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å–å¾—ã™ã‚‹](#llmç”Ÿæˆã®è«–æ–‡ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å–å¾—ã™ã‚‹)
6. [ç‹¬è‡ªã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆã™ã‚‹](#ç‹¬è‡ªã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆã™ã‚‹)
   - [ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãŒæä¾›ã™ã‚‹ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ](#ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãŒæä¾›ã™ã‚‹ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ)
7. [ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒªã‚½ãƒ¼ã‚¹](#ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒªã‚½ãƒ¼ã‚¹)
8. [AI Scientistã®å¼•ç”¨](#ai-scientistã®å¼•ç”¨)
9. [ã‚ˆãã‚ã‚‹è³ªå•](#ã‚ˆãã‚ã‚‹è³ªå•)
10. [ã‚³ãƒ³ãƒ†ãƒŠåŒ–](#ã‚³ãƒ³ãƒ†ãƒŠåŒ–)

## ã¯ã˜ã‚ã«

ç§ãŸã¡ã¯ã€è«–æ–‡ã§ä½¿ç”¨ã—ãŸ3ã¤ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã‚‰ã¯ã€**NanoGPT**ã€**2D Diffusion**ã€ãŠã‚ˆã³**Grokking**ã®é ˜åŸŸã‚’ã‚«ãƒãƒ¼ã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã‚‰ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½¿ç”¨ã—ã¦ã€AI ScientistãŒã“ã‚Œã‚‰ã®åˆ†é‡ã§ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’ç”Ÿæˆã—ã€å®Ÿé¨“ã‚’è¡Œã†ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‹ã‚‰ã®æ–°ã—ã„ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®è²¢çŒ®ã‚’å—ã‘ä»˜ã‘ã¦ã„ã¾ã™ãŒã€ã“ã‚Œã‚‰ã¯ç§ãŸã¡ã«ã‚ˆã£ã¦ç¶­æŒã•ã‚Œã¦ã„ãªã„ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚æä¾›ã•ã‚ŒãŸ3ã¤ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä»¥å¤–ã®ã™ã¹ã¦ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¯ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®è²¢çŒ®ã§ã™ã€‚

## è¦ä»¶

ã“ã®ã‚³ãƒ¼ãƒ‰ã¯ã€CUDAã¨PyTorchã‚’ä½¿ç”¨ã—ã¦NVIDIA GPUã‚’æ­è¼‰ã—ãŸLinuxã§å®Ÿè¡Œã™ã‚‹ã‚ˆã†ã«è¨­è¨ˆã•ã‚Œã¦ã„ã¾ã™ã€‚ä»–ã®GPUã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®ã‚µãƒãƒ¼ãƒˆã¯ã€[PyTorchã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³](https://pytorch.org/get-started/locally/)ã«å¾“ã†ã“ã¨ã§å¯èƒ½ã§ã™ã€‚ç¾åœ¨ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¯ã€CPUã®ã¿ã®ãƒã‚·ãƒ³ã§ã¯å®Ÿè¡Œã«éå¸¸ã«é•·ã„æ™‚é–“ãŒã‹ã‹ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ä»–ã®ã‚ªãƒšãƒ¬ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã§ã®å®Ÿè¡Œã«ã¯ã€ã‹ãªã‚Šã®èª¿æ•´ãŒå¿…è¦ã§ã™ã€‚

### ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
conda create -n ai_scientist python=3.11
conda activate ai_scientist
# pdflatexã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
sudo apt-get install texlive-full

# PyPIã®è¦ä»¶ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -r requirements.txt
```

**æ³¨:** `texlive-full`ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã«ã¯æ™‚é–“ãŒã‹ã‹ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­ã«[Enterã‚­ãƒ¼ã‚’æŠ¼ã—ç¶šã‘ã‚‹](https://askubuntu.com/questions/956006/pregenerating-context-markiv-format-this-may-take-forever)å¿…è¦ãŒã‚ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚

### ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ã¨APIã‚­ãƒ¼

ç§ãŸã¡ã¯ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚¦ã‚§ã‚¤ãƒˆãƒ¢ãƒ‡ãƒ«ã¨APIå°‚ç”¨ãƒ¢ãƒ‡ãƒ«ã‚’å«ã‚€ã•ã¾ã–ã¾ãªãƒ¢ãƒ‡ãƒ«ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚ä¸€èˆ¬çš„ã«ã€å…ƒã®GPT-4ã®èƒ½åŠ›ã‚’è¶…ãˆã‚‹ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ãƒ¢ãƒ‡ãƒ«ã®ã¿ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ã®å®Œå…¨ãªãƒªã‚¹ãƒˆã«ã¤ã„ã¦ã¯ã€[ã“ã¡ã‚‰](https://github.com/SakanaAI/AI-Scientist/blob/main/ai_scientist/llm.py)ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

#### OpenAI API (GPT-4o, GPT-4o-mini, o1ãƒ¢ãƒ‡ãƒ«)

ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯ã€`OPENAI_API_KEY`ç’°å¢ƒå¤‰æ•°ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

#### Anthropic API (Claude Sonnet 3.5)

ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯ã€`ANTHROPIC_API_KEY`ç’°å¢ƒå¤‰æ•°ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

##### BedrockçµŒç”±ã®Claudeãƒ¢ãƒ‡ãƒ«

[Amazon Bedrock](https://aws.amazon.com/bedrock/)ãŒæä¾›ã™ã‚‹Claudeãƒ¢ãƒ‡ãƒ«ã®å ´åˆã€ä»¥ä¸‹ã®è¿½åŠ ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ï¼š

```bash
pip install anthropic[bedrock]
```

æ¬¡ã«ã€æœ‰åŠ¹ãª[AWSèªè¨¼æƒ…å ±](https://docs.aws.amazon.com/cli/v1/userguide/cli-configure-envvars.html)ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ[AWSãƒªãƒ¼ã‚¸ãƒ§ãƒ³](https://docs.aws.amazon.com/bedrock/latest/userguide/bedrock-regions.html)ã‚’æŒ‡å®šã—ã¾ã™ï¼š

ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®šã—ã¾ã™ï¼š`AWS_ACCESS_KEY_ID`ã€`AWS_SECRET_ACCESS_KEY`ã€`AWS_REGION_NAME`ã€‚

##### Vertex AIçµŒç”±ã®Claudeãƒ¢ãƒ‡ãƒ«

[Vertex AI Model Garden](https://cloud.google.com/model-garden?hl=en)ãŒæä¾›ã™ã‚‹Claudeãƒ¢ãƒ‡ãƒ«ã®å ´åˆã€ä»¥ä¸‹ã®è¿½åŠ ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ï¼š

```bash
pip install google-cloud-aiplatform
pip install anthropic[vertex]
```

æ¬¡ã«ã€æœ‰åŠ¹ãª[Google Cloudãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ](https://cloud.google.com/vertex-ai/docs/authentication)ã®èªè¨¼ã‚’è¨­å®šã—ã¾ã™ã€‚ãŸã¨ãˆã°ã€ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆIDã‚’æä¾›ã—ã¾ã™ï¼š

```bash
export CLOUD_ML_REGION="REGION"           # Model Gardenã®å‘¼ã³å‡ºã—ç”¨
export ANTHROPIC_VERTEX_PROJECT_ID="PROJECT_ID"  # Model Gardenã®å‘¼ã³å‡ºã—ç”¨
export VERTEXAI_LOCATION="REGION"         # Aider/LiteLLMã®å‘¼ã³å‡ºã—ç”¨
export VERTEXAI_PROJECT="PROJECT_ID"      # Aider/LiteLLMã®å‘¼ã³å‡ºã—ç”¨
```

#### DeepSeek API (DeepSeek-Coder-V2)

ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯ã€`DEEPSEEK_API_KEY`ç’°å¢ƒå¤‰æ•°ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

#### OpenRouter API (Llama3.1)

ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯ã€`OPENROUTER_API_KEY`ç’°å¢ƒå¤‰æ•°ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

#### Semantic Scholar API (æ–‡çŒ®æ¤œç´¢)

ç§ãŸã¡ã®ã‚³ãƒ¼ãƒ‰ã¯ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§Semantic Scholar APIã‚­ãƒ¼ï¼ˆ`S2_API_KEY`ï¼‰ã‚’ä½¿ç”¨ã—ã¦ã€[é«˜ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ](https://www.semanticscholar.org/product/api)ã‚’å®Ÿç¾ã§ãã¾ã™ãŒã€åŸå‰‡ã¨ã—ã¦ãã‚Œãªã—ã§ã‚‚å‹•ä½œã™ã‚‹ã¯ãšã§ã™ã€‚Semantic Scholarã«å•é¡ŒãŒã‚ã‚‹å ´åˆã¯ã€æ–‡çŒ®æ¤œç´¢ã¨è«–æ–‡ç”Ÿæˆã®å¼•ç”¨ãƒ•ã‚§ãƒ¼ã‚ºã‚’ã‚¹ã‚­ãƒƒãƒ—ã§ãã¾ã™ã€‚

ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã®ã‚­ãƒ¼ã‚’å¿…ãšæä¾›ã—ã¦ãã ã•ã„ã€‚ä¾‹ï¼š

```bash
export OPENAI_API_KEY="YOUR KEY HERE"
export S2_API_KEY="YOUR KEY HERE"
```

## ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®è¨­å®š

ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ã€è«–æ–‡ã§ä½¿ç”¨ã—ãŸ3ã¤ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®è¨­å®šæ‰‹é †ã‚’æä¾›ã—ã¾ã™ã€‚AI Scientistã®å®Ÿé¨“ã‚’å®Ÿè¡Œã™ã‚‹å‰ã«ã€èˆˆå‘³ã®ã‚ã‚‹ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®è¨­å®šæ‰‹é †ã‚’å®Œäº†ã—ã¦ãã ã•ã„ã€‚

### NanoGPTãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

**èª¬æ˜:** ã“ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¯ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ™ãƒ¼ã‚¹ã®è‡ªå·±å›å¸°æ¬¡ãƒˆãƒ¼ã‚¯ãƒ³äºˆæ¸¬ã‚¿ã‚¹ã‚¯ã‚’èª¿æŸ»ã—ã¾ã™ã€‚

**è¨­å®šæ‰‹é †:**

1. **ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™:**

   ```bash
   python data/enwik8/prepare.py
   python data/shakespeare_char/prepare.py
   python data/text8/prepare.py
   ```

2. **ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ©ãƒ³ã®ä½œæˆï¼ˆãƒã‚·ãƒ³ä¾å­˜ï¼‰:**

   ```bash
   # NanoGPTãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ©ãƒ³ã®è¨­å®š
   # æ³¨: ã¾ãšä¸Šè¨˜ã®æº–å‚™ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼
   cd templates/nanoGPT
   python experiment.py --out_dir run_0
   python plot.py
   ```

### 2D Diffusionãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

**èª¬æ˜:** ã“ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¯ã€ä½æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®æ‹¡æ•£ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½å‘ä¸Šã‚’ç ”ç©¶ã—ã¾ã™ã€‚

**è¨­å®šæ‰‹é †:**

1. **ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«:**

   ```bash
   # 2D Diffusionã®è¨­å®š
   git clone https://github.com/gregversteeg/NPEET.git
   cd NPEET
   pip install .
   pip install scikit-learn
   ```

2. **ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ©ãƒ³ã®ä½œæˆ:**

   ```bash
   # 2D Diffusionãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ©ãƒ³ã®è¨­å®š
   cd templates/2d_diffusion
   python experiment.py --out_dir run_0
   python plot.py
   ```

### Grokkingãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

**èª¬æ˜:** ã“ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¯ã€ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«ãŠã‘ã‚‹ä¸€èˆ¬åŒ–ã¨å­¦ç¿’é€Ÿåº¦ã«é–¢ã™ã‚‹è³ªå•ã‚’èª¿æŸ»ã—ã¾ã™ã€‚

**è¨­å®šæ‰‹é †:**

1. **ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«:**

   ```bash
   # Grokkingã®è¨­å®š
   pip install einops
   ```

2. **ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ©ãƒ³ã®ä½œæˆ:**

   ```bash
   # Grokkingãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ©ãƒ³ã®è¨­å®š
   cd templates/grokking
   python experiment.py --out_dir run_0
   python plot.py
   ```

## AI Scientistã®è«–æ–‡ç”Ÿæˆå®Ÿé¨“ã‚’å®Ÿè¡Œã™ã‚‹

**æ³¨:** ã“ã‚Œã‚‰ã®å®Ÿé¨“ã‚’å®Ÿè¡Œã™ã‚‹å‰ã«ã€ä¸Šè¨˜ã®è¨­å®šæ‰‹é †ã‚’å®Œäº†ã—ã¦ãã ã•ã„ã€‚

```bash
conda activate ai_scientist
# è«–æ–‡ç”Ÿæˆã‚’å®Ÿè¡Œ
python launch_scientist.py --model "gpt-4o-2024-05-13" --experiment nanoGPT_lite --num-ideas 2
python launch_scientist.py --model "claude-3-5-sonnet-20241022" --experiment nanoGPT_lite --num-ideas 2
```

è¤‡æ•°ã®GPUã‚’æŒã£ã¦ã„ã‚‹å ´åˆã¯ã€`--parallel`ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ä½¿ç”¨ã—ã¦ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’è¤‡æ•°ã®GPUã«ä¸¦åˆ—åŒ–ã—ã¾ã™ã€‚

## LLMç”Ÿæˆã®è«–æ–‡ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å–å¾—ã™ã‚‹

```python
import openai
from ai_scientist.perform_review import load_paper, perform_review

client = openai.OpenAI()
model = "gpt-4o-2024-05-13"

# PDFãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è«–æ–‡ã‚’èª­ã¿è¾¼ã‚€ï¼ˆç”Ÿãƒ†ã‚­ã‚¹ãƒˆï¼‰
paper_txt = load_paper("report.pdf")

# ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ã‚£ã‚¯ã‚·ãƒ§ãƒŠãƒªã‚’å–å¾—
review = perform_review(
    paper_txt,
    model,
    client,
    num_reflections=5,
    num_fs_examples=1,
    num_reviews_ensemble=5,
    temperature=0.1,
)

# ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœã‚’ç¢ºèª
review["Overall"]    # å…¨ä½“ã‚¹ã‚³ã‚¢ï¼ˆ1-10ï¼‰
review["Decision"]   # 'Accept'ã¾ãŸã¯'Reject'
review["Weaknesses"] # å¼±ç‚¹ã®ãƒªã‚¹ãƒˆï¼ˆæ–‡å­—åˆ—ï¼‰
```

ãƒãƒƒãƒåˆ†æã‚’å®Ÿè¡Œã™ã‚‹ã«ã¯ï¼š

```bash
cd review_iclr_bench
python iclr_analysis.py --num_reviews 500 --batch_size 100 --num_fs_examples 1 --num_reflections 5 --temperature 0.1 --num_reviews_ensemble 5
```

## ç‹¬è‡ªã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆã™ã‚‹

**The AI Scientist**ã«æ¢æ±‚ã—ã¦ã»ã—ã„ç ”ç©¶åˆ†é‡ãŒã‚ã‚‹å ´åˆã¯ã€ç‹¬è‡ªã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆã™ã‚‹ã®ã¯ç°¡å˜ã§ã™ã€‚ä¸€èˆ¬çš„ã«ã€æ—¢å­˜ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®æ§‹é€ ã«å¾“ã„ã¾ã™ã€‚ã“ã‚Œã‚‰ã¯æ¬¡ã®ã‚ˆã†ã«æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ï¼š

- `experiment.py` â€” ã“ã‚Œã¯ã€ã‚³ã‚¢ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒå«ã¾ã‚Œã‚‹ãƒ¡ã‚¤ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ã™ã€‚`--out_dir`å¼•æ•°ã‚’å–ã‚Šã€å®Ÿè¡Œçµæœã‚’ä¿å­˜ã™ã‚‹ãƒ•ã‚©ãƒ«ãƒ€ã‚’æŒ‡å®šã—ã¾ã™ã€‚
- `plot.py` â€” ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€`run`ãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰æƒ…å ±ã‚’å–å¾—ã—ã€ãƒ—ãƒ­ãƒƒãƒˆã‚’ä½œæˆã—ã¾ã™ã€‚ã‚³ãƒ¼ãƒ‰ã¯æ˜ç¢ºã§ç·¨é›†ã—ã‚„ã™ã„ã‚‚ã®ã§ã‚ã‚‹ã¹ãã§ã™ã€‚
- `prompt.json` â€” ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«é–¢ã™ã‚‹æƒ…å ±ã‚’ã“ã“ã«è¨˜è¼‰ã—ã¾ã™ã€‚
- `seed_ideas.json` â€” ã“ã“ã«ä¾‹ã®ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’é…ç½®ã—ã¾ã™ã€‚ä¾‹ãŒãªãã¦ã‚‚ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’ç”Ÿæˆã—ã€æœ€è‰¯ã®ã‚‚ã®ã‚’1ã¤ã‹2ã¤é¸ã‚“ã§ã“ã“ã«é…ç½®ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚
- `latex/template.tex` â€” ç§ãŸã¡ã®LaTeXãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ãŒã€äº‹å‰ã«èª­ã¿è¾¼ã¾ã‚ŒãŸå¼•ç”¨ã‚’æœŸå¾…ã•ã‚Œã‚‹ã‚‚ã®ã«ç½®ãæ›ãˆã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚

æ–°ã—ã„ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’æ©Ÿèƒ½ã•ã›ã‚‹ãŸã‚ã®éµã¯ã€åŸºæœ¬çš„ãªãƒ•ã‚¡ã‚¤ãƒ«åã¨å‡ºåŠ›JSONã‚’æ—¢å­˜ã®å½¢å¼ã«ä¸€è‡´ã•ã›ã‚‹ã“ã¨ã§ã™ã€‚ãã‚Œä»¥å¤–ã®ã™ã¹ã¦ã¯è‡ªç”±ã«å¤‰æ›´ã§ãã¾ã™ã€‚
ã¾ãŸã€`template.tex`ãƒ•ã‚¡ã‚¤ãƒ«ãŒãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«é©ã—ãŸæ­£ã—ã„å¼•ç”¨ã‚¹ã‚¿ã‚¤ãƒ«/åŸºæœ¬ãƒ—ãƒ­ãƒƒãƒˆã‚’ä½¿ç”¨ã™ã‚‹ã‚ˆã†ã«æ›´æ–°ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

### ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãŒæä¾›ã™ã‚‹ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

ç§ãŸã¡ã¯ã€æ–°ã—ã„ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®å½¢ã§ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®è²¢çŒ®ã‚’æ­“è¿ã—ã¾ã™ã€‚ã“ã‚Œã‚‰ã¯ç§ãŸã¡ã«ã‚ˆã£ã¦ç¶­æŒã•ã‚Œã¦ã„ã¾ã›ã‚“ãŒã€ä»–ã®äººã€…ã«ã‚ãªãŸã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ç´¹ä»‹ã™ã‚‹ã“ã¨ã‚’å–œã‚“ã§ã„ã¾ã™ã€‚ä»¥ä¸‹ã«ã€ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãŒæä¾›ã™ã‚‹ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¨ãã®ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆPRï¼‰ã¸ã®ãƒªãƒ³ã‚¯ã‚’ç¤ºã—ã¾ã™ï¼š

- æ„ŸæŸ“ç—‡ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ï¼ˆ`seir`ï¼‰ - [PR #137](https://github.com/SakanaAI/AI-Scientist/pull/137)
- MobileNetV3ã‚’ä½¿ç”¨ã—ãŸç”»åƒåˆ†é¡ï¼ˆ`mobilenetV3`ï¼‰ - [PR #141](https://github.com/SakanaAI/AI-Scientist/pull/141)
- Sketch RNNï¼ˆ`sketch_rnn`ï¼‰ - [PR #143](https://github.com/SakanaAI/AI-Scientist/pull/143)

*ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®è²¢çŒ®ã®ãŸã‚ã«äºˆç´„ã•ã‚Œã¦ã„ã¾ã™ã€‚ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ãƒªã‚¹ãƒˆã«è¿½åŠ ã™ã‚‹ãŸã‚ã«ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’æå‡ºã—ã¦ãã ã•ã„ï¼PRã®èª¬æ˜ã«ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’èª¬æ˜ã—ã€ç”Ÿæˆã•ã‚ŒãŸè«–æ–‡ã®ä¾‹ã‚‚ç¤ºã—ã¦ãã ã•ã„ã€‚*

## ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒªã‚½ãƒ¼ã‚¹

ç§ãŸã¡ã¯ã€ä»–ã®ãƒªãƒã‚¸ãƒˆãƒªã‹ã‚‰ã®ã‚³ãƒ¼ãƒ‰ã‚’å¤šç”¨ã—ã¦ã„ã‚‹3ã¤ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚ä»¥ä¸‹ã«ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚’ç¤ºã—ã¾ã™ï¼š

- **NanoGPTãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ**ã¯ã€[NanoGPT](https://github.com/karpathy/nanoGPT)ã¨ã“ã®[PR](https://github.com/karpathy/nanoGPT/pull/254)ã®ã‚³ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚
- **2D Diffusionãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ**ã¯ã€[tiny-diffusion](https://github.com/tanelp/tiny-diffusion)ã€[ema-pytorch](https://github.com/lucidrains/ema-pytorch)ã€ãŠã‚ˆã³[Datasaur](https://www.research.autodesk.com/publications/same-stats-different-graphs/)ã®ã‚³ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚
- **Grokkingãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ**ã¯ã€[Sea-Snell/grokking](https://github.com/Sea-Snell/grokking)ãŠã‚ˆã³[danielmamay/grokking](https://github.com/danielmamay/grokking)ã®ã‚³ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚

ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®é–‹ç™ºè€…ã«æ„Ÿè¬ã—ã€ãã®ä½œæ¥­ã‚’åˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã«ã—ã¦ãã‚ŒãŸã“ã¨ã«æ„Ÿè¬ã—ã¾ã™ã€‚

## AI Scientistã®å¼•ç”¨

**The AI Scientist**ã‚’ç ”ç©¶ã«ä½¿ç”¨ã™ã‚‹å ´åˆã¯ã€æ¬¡ã®ã‚ˆã†ã«å¼•ç”¨ã—ã¦ãã ã•ã„ï¼š

```
@article{lu2024aiscientist,
  title={The {AI} {S}cientist: Towards Fully Automated Open-Ended Scientific Discovery},
  author={Lu, Chris and Lu, Cong and Lange, Robert Tjarko and Foerster, Jakob and Clune, Jeff and Ha, David},
  journal={arXiv preprint arXiv:2408.06292},
  year={2024}
}
```

## ã‚ˆãã‚ã‚‹è³ªå•

The AI Scientistã«é–¢ã™ã‚‹è³ªå•ãŒã‚ã‚‹å ´åˆã¯ã€ã¾ãšç§ãŸã¡ã®è«–æ–‡ã‚’èª­ã‚€ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚

**The AI Scientistã‚’å®Ÿè¡Œã™ã‚‹éš›ã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã®ã¯ãªãœã§ã™ã‹ï¼Ÿ**

ãƒ¡ã‚¤ãƒ³ã®å®Ÿé¨“ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œã™ã‚‹å‰ã«ã€ã™ã¹ã¦ã®è¨­å®šã¨æº–å‚™æ‰‹é †ã‚’å®Œäº†ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚

**PDFã‚„ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒç”Ÿæˆã•ã‚Œã¦ã„ãªã„ã®ã¯ãªãœã§ã™ã‹ï¼Ÿ**

The AI Scientistã¯ã€ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã€åŸºç¤ã¨ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã€ãŠã‚ˆã³ã‚¢ã‚¤ãƒ‡ã‚¢ã®è¤‡é›‘ã•ã«å¿œã˜ã¦ã€æˆåŠŸç‡ãŒç•°ãªã‚Šã¾ã™ã€‚ç§ãŸã¡ã®ãƒ¡ã‚¤ãƒ³ã®è«–æ–‡ã‚’å‚ç…§ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚æœ€ã‚‚é«˜ã„æˆåŠŸç‡ã¯Claude Sonnet 3.5ã§è¦³å¯Ÿã•ã‚Œã¾ã™ã€‚ãƒ¬ãƒ“ãƒ¥ãƒ¼ã¯GPT-4oã§è¡Œã†ã®ãŒæœ€é©ã§ã™ã€‚ä»–ã®ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒã‚¤ã‚¢ã‚¹ã‚„å¿…è¦ãªå‡ºåŠ›ã«å¾“ã‚ãªã„å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚

**ç”Ÿæˆã•ã‚Œã‚‹ã‚¢ã‚¤ãƒ‡ã‚¢ã®ã‚³ã‚¹ãƒˆã¯ã©ã‚Œãã‚‰ã„ã§ã™ã‹ï¼Ÿ**

é€šå¸¸ã€Claude Sonnet 3.5ã§1è«–æ–‡ã‚ãŸã‚Š15ãƒ‰ãƒ«æœªæº€ã§ã™ã€‚ã‚ˆã‚Šã‚³ã‚¹ãƒˆåŠ¹æœã®é«˜ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¨ã—ã¦ã€DeepSeek Coder V2ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã‚’æ¢ã™è‰¯ã„å ´æ‰€ã¯ã€[Aiderãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰](https://aider.chat/docs/leaderboards/)ã§ã™ã€‚

**æ›¸ãèµ·ã“ã—ã«é–¢é€£ã™ã‚‹åŸºæœ¬çš„ãªä¼šè­°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’å¤‰æ›´ã™ã‚‹ã«ã¯ã©ã†ã™ã‚Œã°ã‚ˆã„ã§ã™ã‹ï¼Ÿ**

å„ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«å«ã¾ã‚Œã‚‹åŸºæœ¬çš„ãª`template.tex`ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¤‰æ›´ã—ã¾ã™ã€‚

**ç•°ãªã‚‹åˆ†é‡ã®ç ”ç©¶ã‚’The AI Scientistã§å®Ÿè¡Œã™ã‚‹ã«ã¯ã©ã†ã™ã‚Œã°ã‚ˆã„ã§ã™ã‹ï¼Ÿ**

ç•°ãªã‚‹ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®æŒ‡ç¤ºã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚ã“ã®ç¾åœ¨ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã¯ã€ã‚³ãƒ¼ãƒ‰ã§è¡¨ç¾ã§ãã‚‹ã‚¢ã‚¤ãƒ‡ã‚¢ã«åˆ¶é™ã•ã‚Œã¦ã„ã¾ã™ã€‚ãŸã ã—ã€ã“ã®åˆ¶é™ã‚’è§£é™¤ã™ã‚‹ã“ã¨ã¯ã€å°†æ¥ã®ã‚¨ã‚­ã‚µã‚¤ãƒ†ã‚£ãƒ³ã‚°ãªä½œæ¥­ã‚’è¡¨ã—ã¦ã„ã¾ã™ï¼ :)

**æ–°ã—ã„åŸºç¤ãƒ¢ãƒ‡ãƒ«ã®ã‚µãƒãƒ¼ãƒˆã‚’è¿½åŠ ã™ã‚‹ã«ã¯ã©ã†ã™ã‚Œã°ã‚ˆã„ã§ã™ã‹ï¼Ÿ**

æ–°ã—ã„åŸºç¤ãƒ¢ãƒ‡ãƒ«ã®ã‚µãƒãƒ¼ãƒˆã‚’è¿½åŠ ã™ã‚‹ã«ã¯ã€`ai_scientist/llm.py`ã‚’å¤‰æ›´ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚**The AI Scientist**ã«ã¯ã€GPT-4ãƒ¬ãƒ™ãƒ«ã‚ˆã‚Šã‚‚å¤§å¹…ã«å¼±ã„ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã¯ãŠå‹§ã‚ã—ã¾ã›ã‚“ã€‚

**ãªãœãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ©ãƒ³ã‚’è‡ªåˆ†ã§å®Ÿè¡Œã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã®ã§ã™ã‹ï¼Ÿ**

ã“ã‚Œã‚‰ã¯`run_0`ã¨ã—ã¦è¡¨ç¤ºã•ã‚Œã€ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã®é•ã„ã«ã‚ˆã‚‹å®Ÿè¡Œæ™‚é–“ã®æ¯”è¼ƒã®ãŸã‚ã«ã€**The AI Scientist**ã‚’å®Ÿè¡Œã™ã‚‹å„ãƒã‚·ãƒ³ã§å®Ÿè¡Œã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

**Semantic Scholar APIã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹éš›ã«å•é¡ŒãŒã‚ã‚‹å ´åˆã¯ã©ã†ã™ã‚Œã°ã‚ˆã„ã§ã™ã‹ï¼Ÿ**

ç§ãŸã¡ã¯ã€ã‚¢ã‚¤ãƒ‡ã‚¢ã®æ–°è¦æ€§ã‚’ç¢ºèªã—ã€è«–æ–‡ã®æ›¸ãèµ·ã“ã—ã®ãŸã‚ã®å¼•ç”¨ã‚’åé›†ã™ã‚‹ãŸã‚ã«Semantic Scholar APIã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚APIã‚­ãƒ¼ãŒãªã„å ´åˆã‚„APIã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒé…ã„å ´åˆã¯ã€ã“ã‚Œã‚‰ã®ãƒ•ã‚§ãƒ¼ã‚ºã‚’ã‚¹ã‚­ãƒƒãƒ—ã§ãã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚

## ã‚³ãƒ³ãƒ†ãƒŠåŒ–

`experimental/Dockerfile`ã«ã€ã‚³ãƒ³ãƒ†ãƒŠåŒ–ã®å–ã‚Šçµ„ã¿ã«å½¹ç«‹ã¤[ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãŒæä¾›ã™ã‚‹](https://github.com/SakanaAI/AI-Scientist/pull/21)Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’å«ã‚ã¦ã„ã¾ã™ã€‚

ã“ã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’æ¬¡ã®ã‚ˆã†ã«ä½¿ç”¨ã§ãã¾ã™ï¼š

```bash
# ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
docker run -e OPENAI_API_KEY=$OPENAI_API_KEY -v `pwd`/templates:/app/AI-Scientist/templates <AI_SCIENTIST_IMAGE> \
  --model gpt-4o-2024-05-13 \
  --experiment 2d_diffusion \
  --num-ideas 2
```

```bash
# ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–
docker run -it -e OPENAI_API_KEY=$OPENAI_API_KEY \
  --entrypoint /bin/bash \
  <AI_SCIENTIST_IMAGE>
```

## ã‚¹ã‚¿ãƒ¼ãƒ’ã‚¹ãƒˆãƒªãƒ¼

[![Star History Chart](https://api.star-history.com/svg?repos=SakanaAI/AI-Scientist&type=Date)](https://star-history.com/#SakanaAI/AI-Scientist&Date)
